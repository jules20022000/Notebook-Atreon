{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION OF SS AND DETECT MOST IMPORTANT FEATURES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import re\n",
    "import scipy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create train data with one hot encoding for MLL\n",
    "severity_train = pd.read_csv(\"train_handmade.csv\", sep=';')\n",
    "mll_train = pd.get_dummies(severity_train[\"MLL\"])\n",
    "severity_train = pd.concat([severity_train, mll_train], axis=1)\n",
    "\n",
    "# Create test data with one hot encoding for MLL\n",
    "severity_test = pd.read_csv(\"test_handmade.csv\", sep=';')\n",
    "mll_test = pd.get_dummies(severity_test[\"MLL\"])\n",
    "severity_test = pd.concat([severity_test, mll_test], axis=1)\n",
    "\n",
    "# Drop the MLL column that is useless now  \n",
    "severity_train = severity_train.drop(columns=[\"MLL\", \"fatigue\", \"breathing problem\", \n",
    "                                             \"concentration\", \"general health\", \"ease of activity\",\n",
    "                                             \"overall pain\", \"sleep quality\", \"age\"], axis=1)\n",
    "severity_test = severity_test.drop(columns=[\"MLL\", \"fatigue\", \"breathing problem\", \n",
    "                                           \"concentration\", \"general health\", \"ease of activity\",\n",
    "                                           \"overall pain\", \"sleep quality\", \"age\"], axis=1)\n",
    "\n",
    "# get same columns for train and test data\n",
    "missing_cols = set(severity_train.columns) - set(severity_test.columns)\n",
    "\n",
    "for c in missing_cols:\n",
    "    severity_test[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "severity_test = severity_test[severity_train.columns]\n",
    "\n",
    "# don t forget to drop the SS columns which was added because present in the train but not in the test\n",
    "severity_test = severity_test.drop(\"severity score\", axis=1)\n",
    "\n",
    "severity_test\n",
    "severity_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize = severity_train.shape[0]\n",
    "#severity_train[\"severity score\"] = severity_train[\"severity score\"].apply(np.log)\n",
    "print(severity_test.shape)\n",
    "print(severity_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_names = severity_train[\"name\"]\n",
    "test_names = severity_test[\"name\"]\n",
    "\n",
    "severity_test.drop(\"name\", axis=1, inplace=True)\n",
    "severity_train.drop(\"name\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (We dont ignore the na or missing in train data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor #as gbr as rfr\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_const = 80 #always use the same one value for all model tuning process\n",
    "test_ratio_const = 0.2 \n",
    "train_data   = severity_train.drop(\"severity score\", axis=1)\n",
    "train_target = severity_train[['severity score']]\n",
    "test_data    = severity_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_target,\\\n",
    "                                                    test_size=test_ratio_const, random_state=rs_const)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. linear regression:\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model.predict(X_train))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ridge\n",
    "grid_param = [{'alpha': np.logspace(-4, 4, 20)}]\n",
    "\n",
    "gs = GridSearchCV(estimator=linear_model.Ridge(random_state=rs_const), param_grid=grid_param, cv=5)\n",
    "\n",
    "gs.fit(X_train_std, y_train)\n",
    "\n",
    "#cv_results_, grid_scores_ (to obsolete), best_estimator_, best_params_, best_score_\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best score : {}'.format(gs.best_score_))\n",
    "#print('')\n",
    "model = gs.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model.predict(X_train_std))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model.predict(X_test_std))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model.coef_.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. lasso \n",
    "# max_iter = 1000, if not enough better increase alpha to proceed, \n",
    "# but not increase max_iter, as it mostly won't help much on the slow convergence. \n",
    "grid_param = [{'alpha': np.logspace(-3, 4, 20)}] \n",
    "\n",
    "gs = GridSearchCV(estimator=linear_model.Lasso(random_state=rs_const, normalize=False), param_grid=grid_param, cv=5)\n",
    "\n",
    "gs.fit(X_train_std, y_train)\n",
    "\n",
    "#cv_results_, grid_scores_ (to obsolete), best_estimator_, best_params_, best_score_\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best score : {}'.format(gs.best_score_))\n",
    "#print('')\n",
    "model = gs.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model.predict(X_train_std))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model.predict(X_test_std))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(model.coef_ > 1e-6) / model.coef_.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ElasticNet\n",
    "grid_param = [{'alpha': np.logspace(-2, 4, 20), 'l1_ratio': np.linspace(0.015, 1, 20)}]\n",
    "\n",
    "# Confirmed that setting scoring='neg_mean_squared_error' is the same result as using the default \"R2\" score.\n",
    "gs = GridSearchCV(estimator=linear_model.ElasticNet(random_state=rs_const), param_grid=grid_param, cv=5)\n",
    "\n",
    "gs.fit(X_train_std, y_train)\n",
    "\n",
    "#cv_results_, grid_scores_ (to obsolete), best_estimator_, best_params_, best_score_\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best score : {}'.format(gs.best_score_))\n",
    "#print('')\n",
    "model = gs.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model.predict(X_train_std))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model.predict(X_test_std))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(model.coef_ > 1e-6) / model.coef_.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_param = [{}]\n",
    "\n",
    "# Step\n",
    "#learning_rate:0.1 -> 0.05 -> 0.01 -> 0.005 ->... 0.005 best\n",
    "#n_estimators: 140 -> 280  -> 1000 -> 2000  ->... 3000 best\n",
    "\n",
    "gs = GridSearchCV(estimator = GradientBoostingRegressor(\\\n",
    "                                    learning_rate=0.005,\\\n",
    "                                    n_estimators=3000,\\\n",
    "                                    max_depth=5,\\\n",
    "                                    min_samples_split=7,\\\n",
    "                                    min_samples_leaf=1,\\\n",
    "                                    max_features='sqrt',\\\n",
    "                                    subsample=0.88,\\\n",
    "                                    random_state=rs_const), \\\n",
    "                                    param_grid = grid_param,\\\n",
    "                                    n_jobs=4, cv=5)  \n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "#cv_results_, grid_scores_ (to obsolete), best_estimator_, best_params_, best_score_\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best score : {}'.format(gs.best_score_))\n",
    "#print('')\n",
    "model = gs.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model.predict(X_train))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(\\\n",
    "                                    learning_rate=0.005,\\\n",
    "                                    n_estimators=1000,\\\n",
    "                                    max_depth=5,\\\n",
    "                                    min_samples_split=7,\\\n",
    "                                    min_samples_leaf=1,\\\n",
    "                                    max_features='sqrt',\\\n",
    "                                    subsample=0.88,\\\n",
    "                                    random_state=rs_const)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model.predict(X_train))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sqrt total feature: {}'.format(math.sqrt(X_train.columns.shape[0])))\n",
    "print('40% of total feature: {}'.format(X_train.columns.shape[0] * 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "varImp = pd.DataFrame({'index':X_train.columns, 'feature_importance':model.feature_importances_})\n",
    "varImp.sort_values(by='feature_importance', ascending=False, inplace=True)\n",
    "f, ax = plt.subplots(1, 1, figsize=[12, 9])\n",
    "sns.barplot(x = 'feature_importance', y = 'index', data = varImp.iloc[:9,], ax = ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = [{}]\n",
    "\n",
    "gs = GridSearchCV(estimator = RandomForestRegressor(\\\n",
    "                                    max_features=4,\\\n",
    "                                    n_estimators=200,\\\n",
    "                                    min_samples_split=5,\\\n",
    "                                    min_samples_leaf=1,\\\n",
    "                                    random_state=rs_const,\\\n",
    "                                    n_jobs=-1),\\\n",
    "                  param_grid = grid_param, n_jobs=-1, cv=5)  \n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "#cv_results_, grid_scores_ (to obsolete), best_estimator_, best_params_, best_score_\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best score : {}'.format(gs.best_score_))\n",
    "#print('')\n",
    "model = gs.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model.predict(X_train))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varImp = pd.DataFrame({'index':X_train.columns, 'feature_importance':model.feature_importances_})\n",
    "varImp.sort_values(by='feature_importance', ascending=False, inplace=True)\n",
    "f, ax = plt.subplots(1, 1, figsize=[12, 9])\n",
    "sns.barplot(x = 'feature_importance', y = 'index', data = varImp.iloc[:9,], ax = ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RF best/try:\n",
    "model = RandomForestRegressor(\\\n",
    "            max_features=4,\\\n",
    "            n_estimators=200,\\\n",
    "            min_samples_split=5,\\\n",
    "            min_samples_leaf=1,\\\n",
    "            random_state=rs_const,\\\n",
    "            n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model.predict(X_train))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model.predict(X_test))))\n",
    "\n",
    "varImp = pd.DataFrame({'index':X_train.columns, 'feature_importance':model.feature_importances_})\n",
    "varImp.sort_values(by='feature_importance', ascending=False, inplace=True)\n",
    "f, ax = plt.subplots(1, 1, figsize=[12, 9])\n",
    "sns.barplot(x = 'feature_importance', y = 'index', data = varImp.iloc[:9,], ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best multi model stacking: \n",
    "models = [\n",
    "    # linear model\n",
    "    #linear_model.Lasso(alpha=0.00545559478116852, random_state=rs_const),\n",
    "    linear_model.ElasticNet(alpha=0.01, l1_ratio=1.0, random_state=rs_const),\n",
    " \n",
    "    # conservative random forst model\n",
    "#     RandomForestRegressor(\\\n",
    "#                         max_depth=5,\\\n",
    "#                         max_features='sqrt',\\\n",
    "#                         n_estimators=1000,\\\n",
    "#                         random_state=rs_const,\\\n",
    "#                         n_jobs=-1),\n",
    "    \n",
    "    RandomForestRegressor(\\\n",
    "                        max_features=4,\\\n",
    "                        n_estimators=200,\\\n",
    "                        min_samples_split=5,\\\n",
    "                        min_samples_leaf=1,\\\n",
    "                        random_state=rs_const,\\\n",
    "                        n_jobs=-1),\n",
    "#     RandomForestRegressor(\\\n",
    "#                         max_depth=None,\\\n",
    "#                         max_features=80,\\\n",
    "#                         n_estimators=170,\\\n",
    "#                         random_state=rs_const,\\\n",
    "#                         n_jobs=-1),\n",
    "    \n",
    "    # conservative gbm model\n",
    "#     GradientBoostingRegressor(\\\n",
    "#                         learning_rate=0.005,\\\n",
    "#                         n_estimators=3000,\\\n",
    "#                         max_depth=2,\\\n",
    "#                         min_samples_split=40,\\\n",
    "#                         min_samples_leaf=10,\\\n",
    "#                         max_features=120,\\\n",
    "#                         subsample=0.8,\\\n",
    "#                         random_state=rs_const),\n",
    "    \n",
    "    GradientBoostingRegressor(\\\n",
    "                        learning_rate=0.005,\\\n",
    "                        n_estimators=3000,\\\n",
    "                        max_depth=5,\\\n",
    "                        min_samples_split=7,\\\n",
    "                        min_samples_leaf=1,\\\n",
    "                        max_features='sqrt',\\\n",
    "                        subsample=0.8,\\\n",
    "                        random_state=rs_const)\n",
    "    \n",
    "#     GradientBoostingRegressor(\\\n",
    "#                         learning_rate=0.01,\\\n",
    "#                         n_estimators=2000,\\\n",
    "#                         max_depth=5,\\\n",
    "#                         min_samples_split=28,\\\n",
    "#                         min_samples_leaf=3,\\\n",
    "#                         max_features=63,\\\n",
    "#                         subsample=0.8,\\\n",
    "#                         random_state=rs_const)\n",
    "    ]\n",
    "\n",
    "meta_model = linear_model.LinearRegression(normalize=False) # normalize=True: almost the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Single model selection: best Lasso:\n",
    "model = linear_model.ElasticNet(alpha=0.01, l1_ratio=1.0, random_state=rs_const)\n",
    "\n",
    "model.fit(X_train_std, y_train)\n",
    "\n",
    "final_train_prediction = model.predict(X_train_std)\n",
    "final_test_prediction  = model.predict(X_test_std)\n",
    "\n",
    "print(\"For log severity score: \")\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, final_train_prediction)))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  final_test_prediction)))\n",
    "print(\"\")\n",
    "print(\"For actual severity score: \")\n",
    "print(\"RMSE train: {}\".format(rmse(np.expm1(y_train), np.expm1(final_train_prediction))))\n",
    "print(\"RMSE test : {}\".format(rmse(np.expm1(y_test),  np.expm1(final_test_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "\n",
    "train_data_std = scaler.transform(train_data)\n",
    "test_data_std  = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model = linear_model.ElasticNet(alpha=1.6237767391887210.01, l1_ratio=0.5334210526315789, random_state=rs_const)\n",
    "#model = linear_model.Lasso(alpha=0.00545559478116852, random_state=rs_const)\n",
    "model = RandomForestRegressor(max_features=4,n_estimators=200, min_samples_split=5, \n",
    "                              min_samples_leaf=1, random_state=rs_const, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "varImp = pd.DataFrame({'index':X_train.columns, 'feature_importance':model.feature_importances_})\n",
    "varImp.sort_values(by='feature_importance', ascending=False, inplace=True)\n",
    "f, ax = plt.subplots(1, 1, figsize=[12, 9])\n",
    "sns.barplot(x = 'feature_importance', y = 'index', data = varImp.iloc[:9,], ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 2 linear models (ElasticNet and Lasso) seems to be good to predict score and output very similar results\n",
    "\n",
    "#model = linear_model.ElasticNet(alpha=0.01, l1_ratio=1.0, random_state=rs_const)\n",
    "#model = linear_model.Lasso(alpha=0.00545559478116852, random_state=rs_const)\n",
    "model = RandomForestRegressor(max_features=4, n_estimators=200, min_samples_split=5, \n",
    "                              min_samples_leaf=1, random_state=rs_const, n_jobs=-1)\n",
    "\n",
    "model.fit(train_data_std, train_target)\n",
    "\n",
    "final_train_prediction = model.predict(train_data_std)\n",
    "final_test_prediction  = model.predict(test_data_std)\n",
    "\n",
    "print(\"For log severity score: \")\n",
    "print(\"RMSE train: {}\".format(rmse(train_target, final_train_prediction)))\n",
    "print(\"\")\n",
    "print(\"For actual severity score: \")\n",
    "print(\"RMSE train: {}\".format(rmse(np.expm1(train_target), np.expm1(final_train_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test_prediction = np.expm1(final_test_prediction)\n",
    "\n",
    "final_submission = pd.DataFrame()\n",
    "final_submission['severity score'] = final_test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we obtain with the formula:\n",
    "\n",
    "50%(fatigue)+15%(10–mood) + 15%(10–ease of activity) + 20%(10–general health)\n",
    "\n",
    "MOOD IS CHANGED BY SLEEP QUALITY IN THE CALCUL OF THE FORMULA FOR THE MOMENT \n",
    "\n",
    "    severity score:     \n",
    "0 : 6.4 \\\n",
    "1 : 5.7 \\\n",
    "2 : 5.4\\\n",
    "3 : 2.5\\\n",
    "4 : 8.05\\\n",
    "5 : 6.65 \\\n",
    "6 : 6.3 \\\n",
    "7 : 5.05\\\n",
    "8 : 5.05\\\n",
    "9 : 2.65 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a classification approach !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
